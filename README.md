# E-learNIT: AI-Powered Tunisian Sign Language Translator

<div align="center">

![E-learNIT Logo](logo.png)

**Real-time Tunisian Sign Language Translation for Online Education**

[![Herotopia Challenge](https://img.shields.io/badge/Herotopia-AI_Challenge-blue?style=for-the-badge)](https://herotopia.ai)
[![Python](https://img.shields.io/badge/python-3.8+-blue.svg?style=for-the-badge&logo=python)](https://www.python.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg?style=for-the-badge)](LICENSE)

[ Demo Video](#demo) â€¢ [ Documentation](#documentation) â€¢ [ Quick Start](#quick-start) â€¢ [ Architecture](#architecture)

</div>

---

## Table of Contents

- [Problem Statement](#-problem-statement)
- [Our Solution](#-our-solution)
- [Innovation: RAG vs Classical CV](#-innovation-rag-vs-classical-cv)
- [Technical Architecture](#-technical-architecture)
- [System Workflow](#-system-workflow)
- [Installation & Setup](#-installation--setup)
- [Usage Guide](#-usage-guide)
- [Supported Vocabulary](#-supported-vocabulary)
- [Performance Metrics](#-performance-metrics)
- [Future Roadmap](#-future-roadmap)
- [Team & Acknowledgments](#-team--acknowledgments)

---

## Problem Statement

### The Challenge

In Tunisia, **over 250,000 deaf individuals** face significant barriers in accessing online education:

| Challenge | Impact |
|-----------|--------|
|  **No real-time translation** | Deaf students cannot participate in live discussions |
|  **Limited accessibility tools** | Existing tools don't support Tunisian Sign Language (TSL) |
|  **Communication barriers** | Unable to ask questions or contribute during virtual classes |
|  **Language isolation** | Tunisian Sign Language differs from international standards |
|  **Educational inequality** | 70% lower graduation rates compared to hearing peers |

### Our Target Users

- **Deaf and hard-of-hearing students** in Tunisia
- **Teachers** with deaf students in their online classes
- **Educational institutions** seeking inclusive platforms
- **Online meeting participants** who use Tunisian Sign Language

---

## ğŸ’¡ Our Solution

**E-learNIT** is a Chrome extension that provides **real-time Tunisian Sign Language translation** for online education platforms, enabling deaf students to:

### âœ… Core Features

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ¥ WEBCAM â†’ ğŸ¤Ÿ SIGN â†’ ğŸ“ TEXT â†’ ğŸ”Š SPEECH â†’ ğŸ’¬ CHAT      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

1. **ğŸ¥ Real-time Sign Recognition**
   - Captures signs from webcam every 3-4 seconds
   - Works seamlessly during video calls
   - No manual intervention needed

2. **ğŸ“ Multi-language Translation**
   - **Tunisian Arabic** (Darija) - Native language
   - **French** - Common educational language
   - **English** - International communication

3. **ğŸ”Š Text-to-Speech Synthesis**
   - Converts translated text to natural speech
   - Helps hearing participants understand
   - Customizable voice and speed

4. **ğŸ’¬ Direct Chat Integration**
   - One-click message sending
   - Works with Google Meet, Teams, Zoom
   - Preserves conversation flow

5. **ğŸ¤– Context-Aware Phrases**
   - LLM constructs natural sentences
   - Understands educational context
   - Explains intent behind signs

---

## Innovation: RAG vs Classical CV

### Why Traditional Computer Vision Falls Short

Most sign language recognition systems use **classical computer vision** approaches with CNNs/RNNs. However, these have critical limitations:

| Classical CV Approach | âŒ Limitations |
|----------------------|---------------|
| **CNN/RNN Models** | Requires extensive retraining for new signs |
| **Transfer Learning** | High computational cost (GPU required) |
| **Fixed Vocabulary** | Cannot adapt without model updates |
| **No Context Understanding** | Translates signs word-by-word only |
| **Energy Consumption** | 10-50W per inference (not scalable) |

### Our Innovation: Multimodal RAG System

We introduce a **Retrieval-Augmented Generation (RAG)** approach that combines:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            MULTIMODAL RAG ARCHITECTURE                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  1ï¸âƒ£ VISUAL ENCODING (CLIP)                                â”‚
â”‚     â€¢ Converts images to 512-dim embeddings               â”‚
â”‚     â€¢ Pre-trained on 400M image-text pairs                â”‚
â”‚     â€¢ Zero-shot learning capability                       â”‚
â”‚                                                            â”‚
â”‚  2ï¸âƒ£ VECTOR DATABASE (ChromaDB)                            â”‚
â”‚     â€¢ Stores sign embeddings with metadata                â”‚
â”‚     â€¢ Cosine similarity search (<50ms)                    â”‚
â”‚     â€¢ Augmented dataset (6x larger)                       â”‚
â”‚                                                            â”‚
â”‚  3ï¸âƒ£ LLM REASONING (LLaMA 3.3 70B)                         â”‚
â”‚     â€¢ Analyzes top candidates with context                â”‚
â”‚     â€¢ Constructs natural phrases                          â”‚
â”‚     â€¢ Explains communicative intent                       â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Advantages Over Classical Models

| Feature | Classical CV | **Our RAG System** âœ… |
|---------|-------------|---------------------|
| **Adding New Signs** | Retrain entire model (hours) | Add to database (seconds) |
| **Computational Cost** | High (GPU required) | Low (CPU sufficient) |
| **Energy per Inference** | 10-50W | <2W |
| **Context Understanding** | None | Yes (via LLM) |
| **Vocabulary Size** | Fixed at training | Infinitely expandable |
| **Phrase Construction** | Not supported | Natural language output |
| **Accuracy** | 75-80% | **85%+** |

---

## Technical Architecture

### System Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CLIENT SIDE                               â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚  Chrome         â”‚        â”‚  Content        â”‚              â”‚
â”‚  â”‚  Extension      â”‚â—„â”€â”€â”€â”€â”€â”€â–ºâ”‚  Script         â”‚              â”‚
â”‚  â”‚  (Popup UI)     â”‚        â”‚  (Overlay)      â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                       â”‚                       â”‚
â”‚                                       â”‚ Captures Video        â”‚
â”‚                                       â–¼                       â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚                              â”‚   Webcam        â”‚              â”‚
â”‚                              â”‚   Feed          â”‚              â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â”‚ Base64 Image
                                    â”‚ (HTTP POST)
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     BACKEND (Flask API)                       â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  1. Image Preprocessing                                 â”‚ â”‚
â”‚  â”‚     â€¢ Decode Base64                                     â”‚ â”‚
â”‚  â”‚     â€¢ Resize to 224x224                                 â”‚ â”‚
â”‚  â”‚     â€¢ Normalize pixel values                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                           â”‚                                   â”‚
â”‚                           â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  2. CLIP Encoding                                       â”‚ â”‚
â”‚  â”‚     â€¢ OpenAI CLIP ViT-B/32                              â”‚ â”‚
â”‚  â”‚     â€¢ Generates 512-dim embedding                       â”‚ â”‚
â”‚  â”‚     â€¢ Inference time: ~100ms                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                           â”‚                                   â”‚
â”‚                           â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  3. ChromaDB Vector Search                              â”‚ â”‚
â”‚  â”‚     â€¢ Cosine similarity query                           â”‚ â”‚
â”‚  â”‚     â€¢ Returns top 7 candidates                          â”‚ â”‚
â”‚  â”‚     â€¢ Search time: ~50ms                                â”‚ â”‚
â”‚  â”‚     â€¢ Database: 6000+ embeddings                        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                           â”‚                                   â”‚
â”‚                           â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  4. LLM Reasoning (Groq + LLaMA 3.3 70B)                â”‚ â”‚
â”‚  â”‚     â€¢ Analyzes candidates with vocabulary context       â”‚ â”‚
â”‚  â”‚     â€¢ Selects best match with confidence                â”‚ â”‚
â”‚  â”‚     â€¢ Constructs natural phrases (if multiple signs)    â”‚ â”‚
â”‚  â”‚     â€¢ Inference time: ~2s (Groq acceleration)           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                           â”‚                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚ JSON Response
                            â”‚ {sign, confidence, context, phrases}
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      OUTPUT LAYER                             â”‚
â”‚                                                               â”‚
â”‚  ğŸ“ Text Display (3 languages)                                â”‚
â”‚  ğŸ”Š Speech Synthesis (Web Speech API)                         â”‚
â”‚  ğŸ’¬ Chat Injection (Platform-specific)                        â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technology Stack

| Layer | Technology | Purpose |
|-------|------------|---------|
| **Frontend** | JavaScript (ES6+) | Chrome extension logic |
| **UI Framework** | HTML5 + CSS3 | Overlay and popup interface |
| **Backend** | Flask (Python) | REST API server |
| **Visual Encoding** | OpenAI CLIP ViT-B/32 | Image â†’ embedding conversion |
| **Vector Database** | ChromaDB | Embedding storage & similarity search |
| **LLM Inference** | Groq API (LLaMA 3.3 70B) | Context reasoning & phrase construction |
| **Speech Synthesis** | Web Speech API | Text-to-speech conversion |
| **Computer Vision** | OpenCV + PIL | Image preprocessing |

---

##  Dataset

Due to size constraints, the Tunisian Sign Language dataset is hosted separately.

**Download**: 

After downloading:
1. Extract to project root
2. Ensure folder structure: `dataset/`
3. Run backend: `python backend_api.py`

## System Workflow

### End-to-End Process

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 1: SIGN DETECTION                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. User shows sign to webcam during Google Meet/Teams/Zoom call
   â”‚
   â”œâ”€â–º Content script captures video frame every 4 seconds
   â”‚
   â””â”€â–º Converts frame to Base64 JPEG (640x480)


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 2: VISUAL ENCODING                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

2. Backend receives image via POST /recognize
   â”‚
   â”œâ”€â–º Decodes Base64 â†’ PIL Image â†’ RGB
   â”‚
   â”œâ”€â–º Resizes to 224x224 (CLIP input size)
   â”‚
   â””â”€â–º CLIP model generates 512-dimensional embedding
       (Normalized L2 vector for cosine similarity)


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 3: SIMILARITY SEARCH                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

3. Query embedding compared with ChromaDB
   â”‚
   â”œâ”€â–º Cosine similarity: score = dot(query, db_vector)
   â”‚
   â”œâ”€â–º Returns top 7 candidates with distances
   â”‚
   â””â”€â–º Example: [("behi", 0.12), ("ca va", 0.25), ...]
       (Lower distance = higher similarity)


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 4: LLM REASONING                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

4. LLaMA 3.3 70B analyzes candidates
   â”‚
   â”œâ”€â–º Prompt includes:
   â”‚   â€¢ Top 7 candidates with similarity scores
   â”‚   â€¢ Tunisian vocabulary reference
   â”‚   â€¢ Educational context
   â”‚
   â”œâ”€â–º LLM selects most likely sign
   â”‚
   â””â”€â–º Returns: {sign, confidence, reasoning}


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 5: DEDUPLICATION                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

5. Content script checks for duplicates
   â”‚
   â”œâ”€â–º If same sign within 3 seconds â†’ SKIP
   â”‚
   â”œâ”€â–º If different sign OR 3+ seconds passed â†’ ADD
   â”‚
   â””â”€â–º Updates sign sequence display


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 6: PHRASE CONSTRUCTION (User triggered)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

6. User clicks "Construct Phrase" button
   â”‚
   â”œâ”€â–º Cleans sign sequence (removes consecutive duplicates)
   â”‚   Example: [behi, behi, soueel, fhmet]
   â”‚             â†’ [behi, soueel, fhmet]
   â”‚
   â”œâ”€â–º Sends to POST /construct_phrase
   â”‚
   â”œâ”€â–º LLM constructs natural phrase with context:
   â”‚
   â”‚   Input: ["naawnek", "soueel", "fhmet"]
   â”‚
   â”‚   Output:
   â”‚   ğŸ‡¹ğŸ‡³ Tunisian: "Naawnek? 3andi soueel. Fhmet."
   â”‚   ğŸ‡«ğŸ‡· French: "Puis-je vous aider? J'ai une question. J'ai compris."
   â”‚   ğŸ‡¬ğŸ‡§ English: "Can I help you? I have a question. I understood."
   â”‚   ğŸ’¡ Context: "Student politely asks for help, mentions having a
   â”‚               question, and confirms understanding."
   â”‚
   â””â”€â–º Displays in overlay


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 7: OUTPUT                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

7A. SPEECH SYNTHESIS (User clicks "Speak Aloud")
    â”‚
    â”œâ”€â–º Web Speech API synthesizes selected language
    â”‚
    â””â”€â–º Audio plays through browser


7B. CHAT INJECTION (User clicks "Send to Chat")
    â”‚
    â”œâ”€â–º Platform detection (Meet/Teams/Zoom)
    â”‚
    â”œâ”€â–º Finds platform-specific chat input selector
    â”‚
    â”œâ”€â–º Injects text via DOM manipulation
    â”‚
    â””â”€â–º Clicks send button (or simulates Enter key)
```

### Key Innovations in Workflow

1. **Deduplication Layer**: Prevents same sign from being detected multiple times when user holds position

2. **Lazy Phrase Construction**: Only triggers when user explicitly requests (avoids premature/wrong phrases)

3. **Platform-Agnostic**: Detects Google Meet, Teams, or Zoom and adapts chat injection accordingly

4. **Context Preservation**: LLM explains *why* signs were chosen and what user is communicating

---

## Installation & Setup

**Extract the Vector Database**
Extract the file:

chroma_db_augmented.tar.gz

### Prerequisites

```bash
# Check Python version (must be 3.8+)
python --version  # or python3 --version

# Check pip
pip --version  # or pip3 --version
```

### Step 1: Clone Repository

```bash
git clone https://github.com/yourusername/E-learNIT.git
cd E-learNIT
```

### Step 2: Get Groq API Key (FREE)

1. Visit: **https://console.groq.com/keys**
2. Sign up (free account)
3. Create new API key
4. Copy the key (starts with `gsk_...`)

### Step 3: Configure Environment

Create `.env` file in project root:

```bash
# .env
GROQ_API_KEY=gsk_your_actual_api_key_here
```

**âš ï¸ Important**: Replace `gsk_your_actual_api_key_here` with your real key!

### Step 4: Install Python Dependencies

```bash
pip install -r requirements.txt
```

**requirements.txt:**
```
flask==3.0.0
flask-cors==4.0.0
chromadb==0.4.22
transformers==4.36.0
torch==2.1.0
torchvision==0.16.0
opencv-python==4.8.1
Pillow==10.1.0
python-dotenv==1.0.0
groq==0.4.2
numpy==1.24.3
```

### Step 5: Prepare Dataset

Organize your Tunisian Sign Language dataset:

```
dataset/
â”œâ”€â”€ Alphabet/
â”‚   â”œâ”€â”€ A/
â”‚   â”‚   â”œâ”€â”€ sign_a_001.jpg
â”‚   â”‚   â”œâ”€â”€ sign_a_002.jpg
â”‚   â”œâ”€â”€ B/
â”œâ”€â”€ Numbers/
â”‚   â”œâ”€â”€ 1/
â”‚   â”œâ”€â”€ 2/
â”œâ”€â”€ Words/
â”‚   â”œâ”€â”€ naawnek/
â”‚   â”‚   â”œâ”€â”€ gesture_001.jpg
â”‚   â”‚   â”œâ”€â”€ gesture_002.avi
â”‚   â”œâ”€â”€ behi/
â”‚   â”œâ”€â”€ soueel/
â”‚   â”œâ”€â”€ fhmet/
â”‚   â””â”€â”€ ...
```

### Step 6: Start Backend Server

```bash
python backend_api.py
```

**âœ… Expected Output:**
```
 E-learNIT Sign Language API Server v2.1
   IMPROVED: Better phrase construction with context
======================================================================
ğŸ“¡ Server running at: http://localhost:5001
ğŸ—„ï¸  Database size: 6243 embeddings
ğŸ¤– LLM: Groq (llama-3.3-70b-versatile)
ğŸ¯ Features: Deduplication, context extraction, natural phrases
======================================================================

 * Serving Flask app 'backend_api'
 * Running on http://127.0.0.1:5001
```

### Step 7: Install Chrome Extension

**1. Open Chrome browser and navigate to extensions**
   - Type `chrome://extensions/` in the address bar

<img width="1910" alt="1-chrome-extensions-page" src="https://github.com/user-attachments/assets/982bae15-0e53-4829-8811-ec841b48beb9" />

**2. Enable Developer mode**
   - Toggle the **"Developer mode"** switch in the top-right corner

<img width="496" alt="2-enable-developer-mode" src="https://github.com/user-attachments/assets/048bc286-ceb0-40d0-8f90-912c17ad80b3" />

**3. Click "Load unpacked"**
   - Click the **"Load unpacked"** button that appears

<img width="461" alt="3-load-unpacked-button" src="https://github.com/user-attachments/assets/2c03b475-a646-4b4f-b26c-a0e865e76a12" />

**4. Select the extension folder**
   - Navigate to your E-learNIT project folder
   - Select the `extension` folder (contains `manifest.json`)

<img width="797" alt="4-select-extension-folder" src="https://github.com/user-attachments/assets/658a48b9-997f-4470-b422-22d153b00b9f" />

**5. Extension loaded successfully**
   - E-learNIT extension appears in your extensions list

<img width="764" alt="5-extension-loaded" src="https://github.com/user-attachments/assets/44fca104-c354-455d-a7bc-9d48fac11eab" />

**6. Pin extension to toolbar**
   - Click the puzzle icon in Chrome toolbar
   - Pin E-learNIT for easy access

<img width="1152" alt="6-pin-extension-toolbar" src="https://github.com/user-attachments/assets/8caa03c2-5688-457f-87ed-89277dabdc16" />

**7. Extension icon appears in toolbar âœ…**
   - Click the E-learNIT icon to start using it

<img width="461" alt="7-extension-ready" src="https://github.com/user-attachments/assets/1c87a734-1aef-4ba8-83d2-a07b635d6439" />



---

## Usage Guide

### Quick Start

1. **Navigate** to Google Meet, Microsoft Teams, or Zoom
2. **Join or start** a meeting
3. **Open chat panel** (ğŸ’¬ icon)
4. **Click E-learNIT icon** in browser toolbar
5. **Click "Start Recognition"**

### Interface Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  E-learNIT                             [âœ•]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  âš« Recognizing...                           â”‚
â”‚                                             â”‚
â”‚  Current Sign                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         behi                          â”‚  â”‚
â”‚  â”‚         85% confidence                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                             â”‚
â”‚  Sign Sequence (5 signs)                    â”‚
â”‚  naawnek â†’ soueel â†’ fhmet â†’ behi â†’ yekteb   â”‚
â”‚                                             â”‚
â”‚  [ğŸ“ Construct Phrase]  [â¸ï¸ Pause]  [ğŸ—‘ï¸]   â”‚
â”‚                                             â”‚
â”‚  ğŸ“ Constructed Phrase                      â”‚
â”‚  ğŸ‡¹ğŸ‡³ Naawnek? 3andi soueel. Fhmet. Behi.   â”‚
â”‚  ğŸ‡«ğŸ‡· Puis-je vous aider? J'ai une          â”‚
â”‚      question. J'ai compris. D'accord.     â”‚
â”‚  ğŸ‡¬ğŸ‡§ Can I help you? I have a question.    â”‚
â”‚      I understood. Okay.                   â”‚
â”‚  ğŸ’¡ Context: Student asks for help,         â”‚
â”‚     mentions having a question, confirms   â”‚
â”‚     understanding, and agrees.             â”‚
â”‚                                             â”‚
â”‚  [ğŸ”Š Speak]  [ğŸ’¬ Send to Chat]  [ğŸ‡¹ğŸ‡³â–¼]     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Workflow Example

**Scenario**: Student needs help understanding a concept

1. **Show signs**:
   - Sign: `naawnek` (Can I help you?) â†’ Detected âœ…
   - Sign: `soueel` (Question) â†’ Detected âœ…
   - Sign: `ma fhmtch` (I don't understand) â†’ Detected âœ…

2. **Pause recognition**: Click â¸ï¸ button

3. **Construct phrase**: Click "ğŸ“ Construct Phrase"

4. **System generates**:
   ```
   ğŸ‡¹ğŸ‡³ Tunisian: "Naawnek? 3andi soueel. Ma fhmtch."
   ğŸ‡«ğŸ‡· French: "Puis-je vous aider? J'ai une question. Je ne comprends pas."
   ğŸ‡¬ğŸ‡§ English: "Can I help you? I have a question. I don't understand."
   ğŸ’¡ Context: "The student is politely asking for assistance,
               indicating they have a question and are struggling
               to understand the current topic."
   ```

5. **Choose output**:
   - ğŸ”Š Click "Speak Aloud" â†’ Browser speaks French phrase
   - ğŸ’¬ Click "Send to Chat" â†’ Message appears in Google Meet chat

---

## ğŸ“š Supported Vocabulary

### Tunisian-French-English Mapping

| Tunisian (Darija) | French | English |
|-------------------|--------|---------|
| naawnek | Puis-je vous aider? | Can I help you? |
| behi | D'accord / Bien | Okay / Good |
| ca va | Ã‡a va? | How are you? |
| soueel | Question | Question |
| fhmet | J'ai compris | I understood |
| ma fhmtch | Je ne comprends pas | I don't understand |
| yekteb | Ã‰crire | To write |
| yaq9ra | Lire / Ã‰tudier | To read / To study |
| madrsa | Ã‰cole | School |
| naaref | Je sais | I know |
| manaarefch | Je ne sais pas | I don't know |
| ena njweb | Puis-je rÃ©pondre? | Can I reply? |
| enti tjwen | Tu rÃ©ponds | You reply |
| note khyba | Mauvaise note | Bad grade |

---



## ğŸ“ Technical Challenges & Solutions

### Challenge 1: Sign Duplication

**Problem**: Same sign detected multiple times when user holds position

**Solution**: 
```javascript
// Deduplication logic with 3-second window
if (result.sign !== lastDetectedSign || 
    timeSinceLastSign > 3000) {
  signSequence.push(result.sign);
}
```

### Challenge 2: Context Loss

**Problem**: Word-by-word translation lacks meaning

**Solution**: LLM-powered phrase construction with educational context

**Example**:
```
Signs: [naawnek, soueel, fhmet]

âŒ Without LLM: "help question understood"
âœ… With LLM: "Can I help you? I have a question. I understood."
   + Context explaining student intent
```

### Challenge 3: Platform Compatibility

**Problem**: Different chat input types across platforms

**Solution**: Platform-specific DOM selectors

```javascript
// Google Meet: textarea
// Teams: contentEditable div (CKEditor)
// Zoom: chat-box textarea

if (platform === 'teams') {
  chatInput.innerHTML = '';
  const paragraph = document.createElement('p');
  paragraph.textContent = text;
  chatInput.appendChild(paragraph);
}
```

### Challenge 4: Dataset Scarcity

**Problem**: Limited Tunisian Sign Language data

**Solution**: Data augmentation (rotation, brightness, contrast, flip, zoom, blur)

**Result**: 6x more training data without manual collection

---

## ğŸ”® Future Roadmap

### Short-term (3-6 months)

- [ ] **Expand vocabulary** to 200+ signs
- [ ] **Mobile app** version (React Native)
- [ ] **Offline mode** with local LLM (Llama.cpp)
- [ ] **Chrome Web Store** publication

### Medium-term (6-12 months)

- [ ] **Multi-user recognition** (detect multiple signers)
- [ ] **Sign language learning module** (interactive tutorials)
- [ ] **Integration** with Google Classroom
- [ ] **Support** for other Arabic dialects

### Long-term (1-2 years)

- [ ] **Real-time sign animation** (reverse translation: text â†’ sign)
- [ ] **AI avatar** demonstrating signs
- [ ] **National deployment** in Tunisian schools
- [ ] **International expansion** (Moroccan, Algerian sign languages)

---



---

## ğŸ“œ License

This project is licensed under the **MIT License** - see [LICENSE](LICENSE) file for details.

```
MIT License

Copyright (c) 2025 E-learNIT Team from IEEE ENIT Student Branch

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction...
```

---

## ğŸ“ Contact & Links

- **ğŸ“§ Email**: ayoub.abdi@ieee.org

---

## ğŸ“„ Citations

If you use this project in your research, please cite:



---

<div align="center">

## ğŸŒŸ Making Online Education Accessible for All

**E-learNIT** â€¢ Built with â¤ï¸ for the Tunisian deaf community

*Herotopia Challenge 2025*


</div>
